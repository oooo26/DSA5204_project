% What you plan to reproduce and/or extend from the paper
\section{plan}

We intend to reproduce the Cycle-Consistent GAN model from the selected application article, testing its performance on another dataset-\url(https://paperswithcode.com/dataset/selfie2anime){selfie2anime}.
In the dataset, 69,926 animated character images are first obtained from Anime-Planet1.27,023 face images were extracted using Anime Face Detector2. 
After selecting only female character images and manually removing monochrome images, we collected two datasets of female anime face images of size 3400 and 100 for training and testing data, respectively. 
All the images are resized to 256 x 256 by applying CNN-based image super-resolution algorithm in the end.

More specifically, as part of the extension, we plan to explore redefining the loss function part of the model. 
In the original paper, it is proposed to combine adversarial loss and cycle consistency loss as the full objective for training and learning. 
Since cycle consistency losses do not explicitly decouple structure and appearance, there will be false learning of missing features. 
Furthermore, the model is trained using a fixed ImageNet, in which is full of pre-trained network. 
And it cannot be adaptively applied to other fields. 
We plan to introduce the similarity of two unpaired samples from the perspective of image segmentation to describe the characteristics of deep features as a loss function. 
Finally we rebuild an extended model to test performance, and compare the model results in the dataset used in the original paper.
